{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "The following blocks of code give an overview of this toy example.\n",
    "\n",
    "\"Ramen\" have 6 attributes: label, brand, country of origin, style, rating, and price. The following block shows how we\n",
    "set up a pipeline to generate recommendations for a fake 'user' profile."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "First we'll look at an example of loading up rdf data and running a pipeline to generate and rank \n",
    "recommended ramens for a user."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "from examples.ramen_rec import *\n",
    "from frex.stores import LocalGraph\n",
    "from rdflib import URIRef\n",
    "\n",
    "# the files we will load containing ramen ratings, fake 'user' data, and vector representation of the ramens.\n",
    "data_files = ((RamenUtils.DATA_DIR / \"ramen-ratings.ttl\").resolve(),)\n",
    "user_files = ((RamenUtils.DATA_DIR / \"ramen-users.ttl\").resolve(),)\n",
    "vector_file = RamenUtils.DATA_DIR / \"ramen-vectors.pkl\"\n",
    "\n",
    "# set up a Graph to load and store the ramen data\n",
    "ramen_graph = LocalGraph(file_paths=data_files)\n",
    "# set up the query service to access ramen data from the graph\n",
    "ramen_q = GraphRamenQueryService(queryable=ramen_graph)\n",
    "\n",
    "# similarly, set up the graph and query service for user data\n",
    "user_graph = LocalGraph(file_paths=user_files)\n",
    "ramen_eater_q = GraphRamenEaterQueryService(queryable=user_graph)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Demo retrieve recommendations for ramens eater http://www.frex.com/examples/USR01\n"
     ]
    }
   ],
   "source": [
    "# our dummy user (ramen eater) who we will get recommendations for\n",
    "ramen_eater_uri = URIRef('http://www.frex.com/examples/USR01')\n",
    "target_ramen_eater = ramen_eater_q.get_ramen_eater_by_uri(\n",
    "    ramen_eater_uri=ramen_eater_uri\n",
    ")\n",
    "print(f\"Demo retrieve recommendations for ramens eater {target_ramen_eater.uri}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "# set up a pipeline that will generate and score candidate Ramens for this user\n",
    "ramen_rec_pipe = RecommendForEaterPipeline(\n",
    "    vector_file=vector_file, ramen_query_service=ramen_q\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "candidate ramen label: Science Noodle (X'Mas Edition), style: Pack, rating: 5.0\n",
      "candidate ramen label: Dan Dan Noodle, style: Pack, rating: 5.0\n"
     ]
    }
   ],
   "source": [
    "# pass in the user context and run the pipeline\n",
    "output_candidates = tuple(ramen_rec_pipe(context=RamenEaterContext(ramen_eater_profile=target_ramen_eater)))\n",
    "\n",
    "# show some of the candidate contents\n",
    "for candidate in output_candidates[:2]:\n",
    "    do = candidate.domain_object\n",
    "    print(f'candidate ramen label: {do.label}, style: {do.style}, rating: {do.rating}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example explanations applied to a candidate output by the pipeline: \n",
      "This ramen is identified as being similar to all of the user's favorite ramens.\n",
      "This ramen is not from a country that is prohibited by the eater.\n",
      "This ramen has a high rating score.\n",
      "This ramen is from not a brand that the user likes.\n",
      "This ramen is a style that the user likes.\n",
      "This ramen is from a country that the user likes.\n"
     ]
    }
   ],
   "source": [
    "print('Example explanations applied to a candidate output by the pipeline: ')\n",
    "\n",
    "# we can also look at the explanations applied to the candidate, which gives us some insight into what kind of filtering\n",
    "# and scoring went on in the pipeline.\n",
    "for expl in output_candidates[0].applied_explanations:\n",
    "    print(expl.explanation_string)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can also use constraint solving to produce a combination of highly recommended items.\n",
    "\n",
    "Let's consider an example of making a meal plan for 2 days, eating 3 ramens each day (we'll assume health and dignity\n",
    "are not important considerations for this user).\n",
    "\n",
    "For this meal plan, we want to choose Ramens that are highly scored by the recommendation pipeline for our user.\n",
    "Additionally, we want to apply some constraints:\n",
    "- The total price of ramens eaten for a given day is <= $7.00\n",
    "- The total price of all ramens eaten in the meal plan (2 days x 3 ramens) is <= $13.00\n",
    "- Ratings are important to us, so the combined ratings of ramens eaten each day must be >= 7\n",
    "\n",
    "The following block of code shows how to set up and solve these constraints."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "from frex.utils import ConstraintSolver, ConstraintType\n",
    "\n",
    "# this will initialize a constraint solver,\n",
    "# set it to 2 sections (2 days),\n",
    "# require each section to have 3 items (3 ramens per day),\n",
    "# create a price constraint for each day,\n",
    "# create a rating constraint for each day,\n",
    "# and create a price constraint for all items\n",
    "solution = ConstraintSolver().\\\n",
    "    set_candidates(candidates=output_candidates)\\\n",
    "    .set_sections(num_sections=2)\\\n",
    "    .set_items_per_section(count=3)\\\n",
    "    .add_section_constraint(attribute_name='price', constraint_type=ConstraintType.LEQ, constraint_val=7.0)\\\n",
    "    .add_section_constraint(attribute_name='rating', constraint_type=ConstraintType.GEQ, constraint_val=7)\\\n",
    "    .add_overall_constraint(attribute_name='price', constraint_type=ConstraintType.LEQ, constraint_val=13.0)\\\n",
    "    .solve()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total score of the obtained solution: 18.200000000000003\n",
      "Day 1:\n",
      "total price of ramens for day 1: 6.640000000000001\n",
      "Ramen names, ratings, and scores in day 1:\n",
      "name: Baseball Snack Noodle, rating: 5.0, recommendation score: 3.1\n",
      "name: Traditional Shallot & Onion Oil Noodle, rating: 5.0, recommendation score: 3.1\n",
      "name: Little Prince(ss) Brand Snack Noodles Artificial Mexican Pizza Flavor, rating: 4.0, recommendation score: 2.9000000000000004\n",
      "Day 2:\n",
      "total price of ramens for day 2: 5.930000000000001\n",
      "Ramen names, ratings, and scores in day 2:\n",
      "name: Science Noodle (X'Mas Edition), rating: 5.0, recommendation score: 3.1\n",
      "name: Scallion Oil & Soy Sauce Noodle, rating: 5.0, recommendation score: 3.1\n",
      "name: Sun Dried Noodle - Fruity Soy Bean Paste, rating: 4.0, recommendation score: 2.9000000000000004\n"
     ]
    }
   ],
   "source": [
    "# exploring the solution. This is based on rating scores acquired from the recommender pipeline, so\n",
    "# they don't really mean a whole lot in the context of this toy example besides high score = better\n",
    "print(f'Total score of the obtained solution: {round(solution.overall_score, 2)}')\n",
    "\n",
    "print('Day 1:')\n",
    "print(f'total price of ramens for day 1: {round(solution.sections[0].section_attribute_values[\"price\"], 2)}')\n",
    "print('Ramen names, ratings, and scores in day 1:')\n",
    "for candidate in solution.sections[0].section_candidates:\n",
    "    do = candidate.domain_object\n",
    "    print(f'name: {do.label}, rating: {do.rating}, price: {do.price}, recommendation score: {round(candidate.total_score, 2)}')\n",
    "print('Day 2:')\n",
    "print(f'total price of ramens for day 2: {round(solution.sections[1].section_attribute_values[\"price\"], 2)}')\n",
    "print('Ramen names, ratings, and scores in day 2:')\n",
    "for candidate in solution.sections[1].section_candidates:\n",
    "    do = candidate.domain_object\n",
    "    print(f'name: {do.label}, rating: {do.rating}, price: {do.price}, recommendation score: {round(candidate.total_score, 2)}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can compare this to just using the first few candidates that we got from the recommendation if pipeline. We'll see\n",
    "that some of the first candidates from the pipeline aren't in our solution that was based on constraints since they have\n",
    "a relatively high price.\n",
    "\n",
    "(These recommendations also have a lot of ties in the scores, since the methods used to score them are extremely simple)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: Science Noodle (X'Mas Edition), rating: 5.0, price: 1.93, recommendation score: 3.1\n",
      "name: Dan Dan Noodle, rating: 5.0, price: 2.87, recommendation score: 3.1\n",
      "name: Sichuan Spices Flavor Noodle, rating: 5.0, price: 4.16, recommendation score: 3.1\n",
      "name: Sichuan Spicy Flavor, rating: 5.0, price: 3.91, recommendation score: 3.1\n"
     ]
    }
   ],
   "source": [
    "for candidate in output_candidates[:4]:\n",
    "    do = candidate.domain_object\n",
    "    print(f'name: {do.label}, rating: {do.rating}, price: {do.price}, recommendation score: {round(candidate.total_score, 2)}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}